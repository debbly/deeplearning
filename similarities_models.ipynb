{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I recently went through the Deeplearning.ai hugging face course and really liked reading through the sentence embedding module. In finding similarities amoung sentences, I wondered how similar the different models (OpenAI, Mistral, and Anthropic) are. This notebook is an exploration given the same inputs, how similar are the responses from each model."
      ],
      "metadata": {
        "id": "NyFPvrMFf97J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2WTbEbTL-rs"
      },
      "outputs": [],
      "source": [
        "from transformers.utils import logging\n",
        "logging.set_verbosity_error()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install sentence-transformers"
      ],
      "metadata": {
        "id": "iLMoSCx4Mt4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Install and set up LLM providers"
      ],
      "metadata": {
        "id": "-lZy7plIfo7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install from PyPI\n",
        "!pip install anthropic"
      ],
      "metadata": {
        "id": "PcwuAzDmOj8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "nogfhBwlPDwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mistralai"
      ],
      "metadata": {
        "id": "1MJh9eQmSoZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up OpenAI API call"
      ],
      "metadata": {
        "id": "wB9z-UyIQSRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "openai_client = OpenAI(\n",
        "    api_key=userdata.get('OPENAI_API_KEY'),\n",
        ")\n",
        "\n",
        "completion = openai_client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "gYIZIJ9MPYOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up Anthropic API call"
      ],
      "metadata": {
        "id": "3rh5SlDfQWW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import anthropic\n",
        "from google.colab import userdata\n",
        "\n",
        "anthropic_client = anthropic.Anthropic(\n",
        "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
        "    api_key=userdata.get('ANTHROPIC_API_KEY'),\n",
        ")\n",
        "message = anthropic_client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Hello, Claude. Tell me a short story!\"}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "C5qM1yZOOPI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(message.content[0].text)"
      ],
      "metadata": {
        "id": "aLeU6s1AbpHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up Mistral API Call"
      ],
      "metadata": {
        "id": "rQhoO3MyQYo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "from mistralai.client import MistralClient\n",
        "from mistralai.models.chat_completion import ChatMessage\n",
        "\n",
        "model = \"mistral-tiny\"\n",
        "\n",
        "client = MistralClient(userdata.get('MISTRAL_API_KEY'))\n",
        "\n",
        "mistral_chat_response = client.chat(\n",
        "    model=model,\n",
        "    messages=[ChatMessage(role=\"user\", content=\"What is the best French cheese?\")],\n",
        ")\n",
        "print(mistral_chat_response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "s2hHdQYwQbK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "g8NiBI7qMTfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "NsFPdRwzMVad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Text from providers"
      ],
      "metadata": {
        "id": "ayKQ54JwfXgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate responses from the 3 different services based on the same prompt."
      ],
      "metadata": {
        "id": "Fs9aXCRcTM8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'I am a developer and I want to learn how to code. My speciality is in backend development and I want to get better at front end. Where do I start?'"
      ],
      "metadata": {
        "id": "KcETRKoUNOtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mistral_chat_response = client.chat(\n",
        "    model=model,\n",
        "    messages=[ChatMessage(role=\"user\", content=prompt)],\n",
        ")"
      ],
      "metadata": {
        "id": "V9gAIX1zTi8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anthropic_message = anthropic_client.messages.create(\n",
        "    model=\"claude-3-opus-20240229\",\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "dxE81i8FNVPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_completion = openai_client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": prompt}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "oGHHUAooWCBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the vector calculations of the messages."
      ],
      "metadata": {
        "id": "GugHD6_GXoSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_mistral = model.encode(mistral_chat_response.choices[0].message.content, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "T5QK-GHCXwpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_anthropic = model.encode(anthropic_message.content[0].text, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "GijxI9c5YMi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_openai = model.encode(openai_completion.choices[0].message.content, convert_to_tensor=True)"
      ],
      "metadata": {
        "id": "qY2HCHSyYh7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate cosine similarity among the three different providers"
      ],
      "metadata": {
        "id": "aujlTTB0Y9Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util"
      ],
      "metadata": {
        "id": "wgTLc92uYzyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c1jUVsikZbwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores_mistral_anthropic = util.cos_sim(embeddings_mistral, embeddings_anthropic)"
      ],
      "metadata": {
        "id": "uiq-YzGyYzva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_scores_mistral_anthropic)"
      ],
      "metadata": {
        "id": "rl3wrm_Yb5wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores_mistral_openai = util.cos_sim(embeddings_mistral, embeddings_openai)\n",
        "print(cosine_scores_mistral_openai)"
      ],
      "metadata": {
        "id": "SkYFT8GJZgVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores_openai_anthropic = util.cos_sim(embeddings_openai, embeddings_anthropic)"
      ],
      "metadata": {
        "id": "cXdgCBLIZkX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_scores_openai_anthropic)"
      ],
      "metadata": {
        "id": "dptvlsKxcDPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}